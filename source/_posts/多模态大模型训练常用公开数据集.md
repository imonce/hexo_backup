---
title: 多模态大模型训练常用公开数据集
date: 2024-06-27 20:33:54
tags: [LLM, data set]
mathjax: true
comments: true
---

![](https://raw.githubusercontent.com/imonce/imgs/master/202406272034200.png)

stage1：预训练。为了拥有广泛的视觉-语言知识，我们的模型在弱标注和细粒度数据集的混合上进行训练。我们在第一阶段给予弱标注数据集较高的采样比例，以获得更多样化的知识。

stage2：多任务训练。为了提高MiniGPT-v2在每项任务上的表现，我们在这个阶段只专注于使用细粒度数据集来训练我们的模型。我们排除了像GRIT-20M和LAION这样的弱监督数据集，并根据每项任务的频率更新数据采样比例。这种策略使我们的模型能够优先考虑高质量的对齐图像-文本数据，以在各种任务上实现卓越的性能。

stage3：多模态指令调整。随后，我们专注于使用更多的多模态指令数据集来调整我们的模型，并增强其作为聊天机器人的对话能力。我们继续使用第二阶段的数据集，并添加指令数据集，包括LLaVA（刘等人，2023b）、Flickr30k数据集（Plummer等人，2015）、我们构建的混合多任务数据集，以及语言数据集，Unnatural Instruction（Honovich等人，2022）。我们为第二阶段的细粒度数据集给出较低的数据采样比例，而为新的指令数据集给出较高的数据采样比例。

> Ref:
> https://arxiv.org/pdf/2310.09478v2